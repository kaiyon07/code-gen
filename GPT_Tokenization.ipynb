{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1EwiZYx_7S3",
        "outputId": "5d218b6e-e67c-4d43-dbb3-02e2f22f0821"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hrB4wOCW_Btl"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "# Encoding name - OpenAI models:\n",
        "# o200k_base: gpt-4o, gpt-4o-mini\n",
        "# cl100k_base: gpt-4-turbo, gpt-4, gpt-3.5-turbo, text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large\n",
        "# p50k_base: Codex models, text-davinci-002, text-davinci-003\n",
        "# r50k_base (or gpt2): GPT-3 models like davinci\n",
        "\n",
        "encoding_names = [\"o200k_base\", \"cl100k_base\", \"p50k_base\", \"r50k_base\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_input(encoding_name, input_text):\n",
        "    try:\n",
        "        tokenizer = tiktoken.get_encoding(encoding_name)\n",
        "\n",
        "        token_ids = tokenizer.encode(input_text)\n",
        "\n",
        "        tokens_as_words = [tokenizer.decode([token_id]) for token_id in token_ids]\n",
        "        token_count = len(tokens_as_words)\n",
        "\n",
        "        return tokens_as_words, token_count\n",
        "    except Exception as e:\n",
        "        print(f\"Error with encoding {encoding_name}: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "jBtoWGLlCgrK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = \"\"\"function quicksort(arr) {\n",
        "    if (arr.length <= 1) return arr;\n",
        "    let pivot = arr[Math.floor(arr.length / 2)];\n",
        "    let left = arr.filter(x => x < pivot);\n",
        "    let middle = arr.filter(x => x === pivot);\n",
        "    let right = arr.filter(x => x > pivot);\n",
        "    return quicksort(left).concat(middle, quicksort(right));\n",
        "}\"\"\""
      ],
      "metadata": {
        "id": "MEZqetx-CjA2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for encoding in encoding_names:\n",
        "    tokens, token_count = tokenize_input(encoding, sample_input)\n",
        "    if tokens is not None:\n",
        "        print(f\"Encoding: {encoding}\")\n",
        "        print(\"Tokens (Words/Subwords):\", tokens)\n",
        "        print(\"Token Count:\", token_count)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ53eiLHCk9l",
        "outputId": "6e3288a6-66a5-4606-e7c1-9019acb6588d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding: o200k_base\n",
            "Tokens (Words/Subwords): ['function', ' quick', 'sort', '(arr', ')', ' {\\n', '   ', ' if', ' (', 'arr', '.length', ' <=', ' ', '1', ')', ' return', ' arr', ';\\n', '   ', ' let', ' pivot', ' =', ' arr', '[Math', '.floor', '(arr', '.length', ' /', ' ', '2', ')];\\n', '   ', ' let', ' left', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' <', ' pivot', ');\\n', '   ', ' let', ' middle', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' ===', ' pivot', ');\\n', '   ', ' let', ' right', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' >', ' pivot', ');\\n', '   ', ' return', ' quick', 'sort', '(left', ').', 'concat', '(m', 'iddle', ',', ' quick', 'sort', '(right', '));\\n', '}']\n",
            "Token Count: 82\n",
            "\n",
            "Encoding: cl100k_base\n",
            "Tokens (Words/Subwords): ['function', ' quick', 'sort', '(arr', ')', ' {\\n', '   ', ' if', ' (', 'arr', '.length', ' <=', ' ', '1', ')', ' return', ' arr', ';\\n', '   ', ' let', ' pivot', ' =', ' arr', '[Math', '.floor', '(arr', '.length', ' /', ' ', '2', ')];\\n', '   ', ' let', ' left', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' <', ' pivot', ');\\n', '   ', ' let', ' middle', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' ===', ' pivot', ');\\n', '   ', ' let', ' right', ' =', ' arr', '.filter', '(x', ' =>', ' x', ' >', ' pivot', ');\\n', '   ', ' return', ' quick', 'sort', '(left', ').', 'concat', '(m', 'iddle', ',', ' quick', 'sort', '(right', '));\\n', '}']\n",
            "Token Count: 82\n",
            "\n",
            "Encoding: p50k_base\n",
            "Tokens (Words/Subwords): ['function', ' qu', 'icks', 'ort', '(', 'arr', ')', ' {', '\\n', '   ', ' if', ' (', 'arr', '.', 'length', ' <=', ' 1', ')', ' return', ' arr', ';', '\\n', '   ', ' let', ' pivot', ' =', ' arr', '[', 'Math', '.', 'floor', '(', 'arr', '.', 'length', ' /', ' 2', ')', '];', '\\n', '   ', ' let', ' left', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' <', ' pivot', ');', '\\n', '   ', ' let', ' middle', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' ===', ' pivot', ');', '\\n', '   ', ' let', ' right', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' >', ' pivot', ');', '\\n', '   ', ' return', ' qu', 'icks', 'ort', '(', 'left', ').', 'con', 'cat', '(', 'middle', ',', ' qu', 'icks', 'ort', '(', 'right', '));', '\\n', '}']\n",
            "Token Count: 106\n",
            "\n",
            "Encoding: r50k_base\n",
            "Tokens (Words/Subwords): ['function', ' qu', 'icks', 'ort', '(', 'arr', ')', ' {', '\\n', ' ', ' ', ' ', ' if', ' (', 'arr', '.', 'length', ' <=', ' 1', ')', ' return', ' arr', ';', '\\n', ' ', ' ', ' ', ' let', ' pivot', ' =', ' arr', '[', 'Math', '.', 'floor', '(', 'arr', '.', 'length', ' /', ' 2', ')', '];', '\\n', ' ', ' ', ' ', ' let', ' left', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' <', ' pivot', ');', '\\n', ' ', ' ', ' ', ' let', ' middle', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' ===', ' pivot', ');', '\\n', ' ', ' ', ' ', ' let', ' right', ' =', ' arr', '.', 'filter', '(', 'x', ' =>', ' x', ' >', ' pivot', ');', '\\n', ' ', ' ', ' ', ' return', ' qu', 'icks', 'ort', '(', 'left', ').', 'con', 'cat', '(', 'middle', ',', ' qu', 'icks', 'ort', '(', 'right', '));', '\\n', '}']\n",
            "Token Count: 118\n",
            "\n"
          ]
        }
      ]
    }
  ]
}